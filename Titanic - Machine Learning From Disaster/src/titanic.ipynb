{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dictionary\n",
    "1) sibsp    : # of siblings/spouses on board\\\n",
    "2) parch    : # of parents/children on board\\\n",
    "3) embarked : Port of embarkation (C : Cherbourg, Q : Queenstown, S : Southampto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "DATA_LOCATION = Path('../../data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels = pd.read_csv(DATA_LOCATION / 'gender_submission.csv')\n",
    "\n",
    "use_cols = [\n",
    "    'PassengerId', 'Survived', 'Pclass', \n",
    "    'Sex', 'Age', 'SibSp', 'Parch', \n",
    "    'Fare', 'Embarked'\n",
    "]\n",
    "\n",
    "train_df = pd.read_csv(DATA_LOCATION / 'train.csv', usecols=use_cols)\n",
    "test_df  = pd.read_csv(DATA_LOCATION / 'test.csv')\n",
    "\n",
    "\n",
    "test_df_run = test_df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "large_data = pd.concat([test_df.merge(actual_labels, how='outer', on='PassengerId'), train_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FieldImputer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, field : str, strategy : str = 'mean') -> None :\n",
    "        self.field = field\n",
    "        self.strategy = strategy\n",
    "        self.__field = field\n",
    "        self.imputer = SimpleImputer(strategy=self.strategy)\n",
    "\n",
    "    def fit(self, X : pd.DataFrame, y = None):\n",
    "        return self\n",
    "     \n",
    "    def transform(self, X : pd.DataFrame, y = None) -> pd.DataFrame :\n",
    "        X[self.__field] = self.imputer.fit_transform(X[self.__field].to_numpy().reshape(-1,1)).ravel()\n",
    "        return X\n",
    "        \n",
    "    def fit_transform(self, X : pd.DataFrame, y = None) -> pd.DataFrame :\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X, y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_steps(fields : list[str]) -> list[FieldImputer] :\n",
    "        \n",
    "        def _build_step(field : str) -> FieldImputer :\n",
    "            return (f'{field}_Imputer', FieldImputer(field))\n",
    "        \n",
    "        return [_build_step(field) for field in fields]\n",
    "    \n",
    "class CategoricalEncoderOhe(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, field : str) -> None :\n",
    "        self.field = field\n",
    "        self.__field = field\n",
    "        self.ohe = OneHotEncoder()\n",
    "    \n",
    "    def fit(self, X : pd.DataFrame, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X : pd.DataFrame, y = None) -> pd.DataFrame :\n",
    "        \n",
    "        field_data = X[self.__field].to_numpy().reshape(-1, 1)\n",
    "        transformed = self.ohe.fit_transform(field_data).toarray()\n",
    "\n",
    "        total_unique = np.unique(transformed, axis=0)\n",
    "\n",
    "        columns = [f'{self.__field}_{i}' for i in range(len(total_unique))]\n",
    "\n",
    "        X[columns] = pd.DataFrame(transformed)\n",
    "        \n",
    "        return X.drop(self.__field, axis=1)\n",
    "    \n",
    "    \n",
    "    def fit_transform(self, X : pd.DataFrame, y = None) -> pd.DataFrame :\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X, y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_steps(fields : list[str]) -> list[CategoricalEncoderOhe]:\n",
    "        \n",
    "        def _build_step(field : str) -> CategoricalEncoderOhe :\n",
    "            \n",
    "            return (f'{field}_ohe', CategoricalEncoderOhe(field))\n",
    "            \n",
    "        return [_build_step(field) for field in fields]\n",
    "    \n",
    "class RFWrapper(RandomForestClassifier):\n",
    "    \n",
    "    def fit_transform(self, X : np.ndarray, y : np.ndarray = None) -> np.ndarray :\n",
    "        model = super().fit(X, y)\n",
    "        return model.predict(X)\n",
    "    \n",
    "    def fit_predict(self, X : np.ndarray, y : np.ndarray = None) -> np.ndarray :\n",
    "        return self.fit_transform(X, y)\n",
    "\n",
    "class DataFrameToNumpy(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X : pd.DataFrame, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X : pd.DataFrame, y = None):\n",
    "        return X.to_numpy()\n",
    "    \n",
    "    def fit_transform(self, X : pd.DataFrame, y = None):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X, y)\n",
    "    \n",
    "param_grid = {\n",
    "    'clf__n_estimators' : [5, 10, 25, 50, 100, 200, 500, 1000],\n",
    "    'clf__max_depth'    : [1, 5, 10, 25, 50, 100, 150, 200],\n",
    "    'clf__random_state' : [42]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps = [\n",
    "        (\"embarked_imputer\", FieldImputer(field='Embarked', strategy='most_frequent')), # handles missing values in Embarked, which exist in Train but not Test\n",
    "        *CategoricalEncoderOhe.build_steps(['Pclass', 'Sex', 'Embarked']),\n",
    "        *FieldImputer.build_steps(['Age', 'SibSp', 'Parch', 'Fare']),\n",
    "        (\"pd_converter\", DataFrameToNumpy()),\n",
    "        ('standard_scaler', StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf_pipeline = Pipeline(\n",
    "    steps= [('clf', RFWrapper())]\n",
    ")\n",
    "\n",
    "precleaned_train_data = pipeline.fit_transform(train_df.drop(['PassengerId', 'Survived'], axis=1), train_df['Survived'].values.ravel())\n",
    "\n",
    "\n",
    "gs = GridSearchCV(estimator=clf_pipeline, param_grid=param_grid, cv=10, scoring='accuracy', verbose=2)\n",
    "gs.fit(precleaned_train_data, train_df['Survived'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_params_)\n",
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precleaned_test_data = pipeline.fit_transform(X=test_df_run.drop('PassengerId', axis=1))\n",
    "gs.best_estimator_.score(precleaned_test_data, actual_labels.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = gs.best_estimator_.predict(precleaned_test_data)\n",
    "output = pd.DataFrame({'PassengerId': test_df_run.PassengerId, 'Survived': predicted})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.DataFrame({'PassengerId': test_df_run.PassengerId, 'Survived': predicted, 'Actual' : actual_labels.Survived})\n",
    "(dd['Survived'] == dd['Actual']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    large_data.drop(['Survived', 'Name', 'Ticket', 'Cabin'], axis=1), \n",
    "    large_data['Survived'], \n",
    "    stratify=large_data['Survived'],\n",
    "    train_size=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'clf__n_estimators' : [5, 10, 25, 50, 100, 200, 500, 1000],\n",
    "    'clf__max_depth'    : [1, 5, 10, 25, 50, 100, 150, 200],\n",
    "    'clf__random_state' : [42]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps = [\n",
    "        (\"embarked_imputer\", FieldImputer(field='Embarked', strategy='most_frequent')), # handles missing values in Embarked, which exist in Train but not Test\n",
    "        *CategoricalEncoderOhe.build_steps(['Pclass', 'Sex', 'Embarked']),\n",
    "        *FieldImputer.build_steps(['Age', 'SibSp', 'Parch', 'Fare']),\n",
    "        (\"pd_converter\", DataFrameToNumpy()),\n",
    "        ('standard_scaler', StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf_pipeline = Pipeline(\n",
    "    steps= [('clf', RFWrapper())]\n",
    ")\n",
    "\n",
    "precleaned_train_data = pipeline.fit_transform(X_train.drop(['PassengerId'], axis=1), y_train)\n",
    "\n",
    "\n",
    "gs = GridSearchCV(estimator=clf_pipeline, param_grid=param_grid, cv=10, scoring='accuracy', verbose=2)\n",
    "gs.fit(precleaned_train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_params_)\n",
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipeline(\n",
    "    steps = [\n",
    "        (\"embarked_imputer\", FieldImputer(field='Embarked', strategy='most_frequent')), # handles missing values in Embarked, which exist in Train but not Test\n",
    "        *CategoricalEncoderOhe.build_steps(['Pclass', 'Sex', 'Embarked']),\n",
    "        *FieldImputer.build_steps(['Age', 'SibSp', 'Parch', 'Fare']),\n",
    "    ]\n",
    ").fit_transform(X=X_test.drop(['PassengerId', 'Pclass_0', 'Pclass_1', 'Pclass_2'], axis=1)).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precleaned_test_data = pipeline.fit_transform(X=X_test.drop(['PassengerId', 'Pclass_0', 'Pclass_1', 'Pclass_2'], axis=1))\n",
    "gs.best_estimator_.score(precleaned_test_data, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = gs.best_estimator_.predict(precleaned_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop(['PassengerId', 'Pclass_0', 'Pclass_1', 'Pclass_2'], axis=1).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
