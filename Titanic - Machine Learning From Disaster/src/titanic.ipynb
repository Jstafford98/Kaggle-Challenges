{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "DATA_LOCATION = Path('../../data/titanic/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameEstimateTransformMixin(BaseEstimator, TransformerMixin):\n",
    "    ''' \n",
    "        Provides so basic functionality for creating pipeline steps that handle \n",
    "        pandas dataframes\n",
    "    '''\n",
    "    \n",
    "    def fit(self, X : pd.DataFrame, y = None):\n",
    "        ''' exists solely for compatability'''\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X : pd.DataFrame, y = None) -> pd.DataFrame :\n",
    "        ''' this has to be implemented by subclasses '''\n",
    "        raise NotImplementedError(\"Transform must be implemented\")\n",
    "    \n",
    "    def fit_transform(self, X : pd.DataFrame, y = None) -> pd.DataFrame :\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X, y)\n",
    "\n",
    "class FieldImputer(DataFrameEstimateTransformMixin):\n",
    "    '''\n",
    "        Wrapper around the sklearn SimpleImputer for working with DataFrame objects in a \n",
    "        data normalization pipeline\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, field : str, strategy : str = 'mean') -> None :\n",
    "        self.field = field\n",
    "        self.strategy = strategy\n",
    "        self.__field = field\n",
    "        self.imputer = SimpleImputer(strategy=self.strategy)\n",
    "\n",
    "    def transform(self, X : pd.DataFrame, y = None) -> pd.DataFrame :\n",
    "        logger.info(f\"Imputing the {self.strategy} for NaN values in {self.__field}\")\n",
    "        X[self.__field] = self.imputer.fit_transform(X[self.__field].to_numpy().reshape(-1,1)).ravel()\n",
    "        return X\n",
    "\n",
    "    @staticmethod\n",
    "    def build_steps(fields : list[str]) -> list[FieldImputer] :\n",
    "        \n",
    "        def _build_step(field : str) -> FieldImputer :\n",
    "            return (f'{field}_Imputer', FieldImputer(field))\n",
    "        \n",
    "        return [_build_step(field) for field in fields]\n",
    "    \n",
    "class CategoricalEncoderOhe(DataFrameEstimateTransformMixin):\n",
    "    \n",
    "    def __init__(self, field : str) -> None :\n",
    "        self.field = field\n",
    "        self.__field = field\n",
    "        self.ohe = OneHotEncoder()\n",
    "    \n",
    "    def transform(self, X : pd.DataFrame, y = None) -> pd.DataFrame :\n",
    "        logger.info(f\"One Hot Encoding categorical column {self.__field}\")\n",
    "        field_data = X[self.__field].to_numpy().reshape(-1, 1)\n",
    "        transformed = self.ohe.fit_transform(field_data).toarray()\n",
    "\n",
    "        total_unique = np.unique(transformed, axis=0)\n",
    "\n",
    "        columns = [f'{self.__field}_{i}' for i in range(len(total_unique))]\n",
    "\n",
    "        X[columns] = pd.DataFrame(transformed)\n",
    "        \n",
    "        return X.drop(self.__field, axis=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_steps(fields : list[str]) -> list[CategoricalEncoderOhe]:\n",
    "        \n",
    "        def _build_step(field : str) -> CategoricalEncoderOhe :\n",
    "            \n",
    "            return (f'{field}_ohe', CategoricalEncoderOhe(field))\n",
    "            \n",
    "        return [_build_step(field) for field in fields]\n",
    "    \n",
    "class DataFrameToNumpy(DataFrameEstimateTransformMixin):\n",
    "    ''' \n",
    "        this is used following a sequence of DataFrameEstimateTransformMixin objects \n",
    "        to make it a numpy array so the data is comptible with later on steps in the\n",
    "        pipeline\n",
    "    '''\n",
    "    \n",
    "    def transform(self, X : pd.DataFrame, y = None) -> np.ndarray :\n",
    "        return X.to_numpy()\n",
    "    \n",
    "class RFWrapper(RandomForestClassifier):\n",
    "    ''' This allows us to put the RandomForestClassifier into Pipelines that expect fit_transform '''\n",
    "    \n",
    "    def fit_transform(self, X : np.ndarray, y : np.ndarray = None) -> np.ndarray :\n",
    "        model = super().fit(X, y)\n",
    "        return model.predict(X)\n",
    "    \n",
    "    def fit_predict(self, X : np.ndarray, y : np.ndarray = None) -> np.ndarray :\n",
    "        return self.fit_transform(X, y)\n",
    "\n",
    "def predict_and_save_results(\n",
    "    clf : RandomForestClassifier, \n",
    "    X_test : np.ndarray, \n",
    "    passenger_ids : pd.Series, \n",
    "    filename : str = 'submission.csv'\n",
    "    ) -> None :\n",
    "    \n",
    "    predictions = clf.predict(X_test)\n",
    "    output = pd.DataFrame({'PassengerId' : passenger_ids, 'Survived' : predictions})\n",
    "    output.to_csv(DATA_LOCATION / filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-01-06 16:08:50.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mLoading data\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mBuilding normalization pipeline\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mBuilding classifier pipeline\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mCleaning training data\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtransform\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mImputing the most_frequent for NaN values in Embarked\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtransform\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mOne Hot Encoding categorical column Pclass\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtransform\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mOne Hot Encoding categorical column Sex\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtransform\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mOne Hot Encoding categorical column Embarked\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtransform\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mImputing the mean for NaN values in Age\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtransform\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mImputing the mean for NaN values in SibSp\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtransform\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mImputing the mean for NaN values in Parch\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtransform\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mImputing the mean for NaN values in Fare\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mCleaning testing data\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtransform\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mImputing the most_frequent for NaN values in Embarked\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtransform\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mOne Hot Encoding categorical column Pclass\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtransform\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mOne Hot Encoding categorical column Sex\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtransform\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mOne Hot Encoding categorical column Embarked\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtransform\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mImputing the mean for NaN values in Age\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtransform\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mImputing the mean for NaN values in SibSp\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtransform\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mImputing the mean for NaN values in Parch\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtransform\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mImputing the mean for NaN values in Fare\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mBuilding GridSearchCV\u001b[0m\n",
      "\u001b[32m2024-01-06 16:08:50.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mFitting GridSerachCV\u001b[0m\n",
      "\u001b[32m2024-01-06 16:11:19.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mBest Train Params: {'clf__max_depth': 10, 'clf__n_estimators': 50, 'clf__random_state': 42}\u001b[0m\n",
      "\u001b[32m2024-01-06 16:11:19.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mBest Train Score :  0.83\u001b[0m\n",
      "\u001b[32m2024-01-06 16:11:20.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mBest Test Score  :  0.87\u001b[0m\n",
      "\u001b[32m2024-01-06 16:11:20.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mSaving predictions\u001b[0m\n",
      "\u001b[32m2024-01-06 16:11:20.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1mComplete.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "use_cols = [\n",
    "    'PassengerId', 'Survived', 'Pclass', \n",
    "    'Sex', 'Age', 'SibSp', 'Parch', \n",
    "    'Fare', 'Embarked'\n",
    "]\n",
    "\n",
    "logger.info(\"Loading data\")\n",
    "actual_labels = pd.read_csv(DATA_LOCATION / 'gender_submission.csv')\n",
    "train_df = pd.read_csv(DATA_LOCATION / 'train.csv', usecols=use_cols)\n",
    "test_df  = pd.read_csv(DATA_LOCATION / 'test.csv').drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "logger.info(\"Building normalization pipeline\")\n",
    "normalization_pipeline = Pipeline(\n",
    "    steps = [\n",
    "        (\"embarked_imputer\", FieldImputer(field='Embarked', strategy='most_frequent')), # handles missing values in Embarked, which exist in Train but not Test\n",
    "        *CategoricalEncoderOhe.build_steps(['Pclass', 'Sex', 'Embarked']),\n",
    "        *FieldImputer.build_steps(['Age', 'SibSp', 'Parch', 'Fare']),\n",
    "        (\"pd_converter\", DataFrameToNumpy()),\n",
    "        ('standard_scaler', StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger.info(\"Building classifier pipeline\")\n",
    "clf_pipeline = Pipeline(\n",
    "    steps= [('clf', RFWrapper())]\n",
    ")\n",
    "\n",
    "logger.info(\"Cleaning training data\")\n",
    "precleaned_train_data = normalization_pipeline.fit_transform(\n",
    "    train_df.drop(['PassengerId', 'Survived'], axis=1), \n",
    "    train_df['Survived'].values.ravel()\n",
    ")\n",
    "\n",
    "logger.info(\"Cleaning testing data\")\n",
    "precleaned_test_data = normalization_pipeline.fit_transform(test_df.drop('PassengerId', axis=1))\n",
    "\n",
    "logger.info(\"Building GridSearchCV\")\n",
    "param_grid = {\n",
    "    'clf__n_estimators' : [5, 10, 25, 50, 100, 200, 500, 1000],\n",
    "    'clf__max_depth'    : [1, 5, 10, 25, 50, 100, 150, 200],\n",
    "    'clf__random_state' : [42]\n",
    "}\n",
    "gs = GridSearchCV(estimator=clf_pipeline, param_grid=param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "logger.info(\"Fitting GridSerachCV\")\n",
    "gs.fit(precleaned_train_data, train_df['Survived'].values.ravel())\n",
    "\n",
    "logger.info(f'Best Train Params: {gs.best_params_}')\n",
    "logger.info(f'Best Train Score : {gs.best_score_ : .2f}')\n",
    "logger.info(f'Best Test Score  : {gs.best_estimator_.score(precleaned_test_data, actual_labels.Survived) : .2f}')\n",
    "\n",
    "logger.info(f\"Saving predictions\")\n",
    "predict_and_save_results(gs.best_estimator_, precleaned_test_data, test_df.PassengerId)\n",
    "\n",
    "logger.info(\"Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
